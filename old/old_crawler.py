from bs4 import BeautifulSoup

import requests
import string 
import re
import random
import json

starting_url="https://chrome.google.com/webstore/category/extensions"
# converting specified web page into beautifulsoup format
def bsoup(url):
    source_code=requests.get(url)
    plain_text=source_code.text
    soup=BeautifulSoup(plain_text, "html.parser")
    return soup

def get_extension_script(url):
    soup = bsoup(url)
    extension_script_data = soup.find("script", {"id":"cws-model-data"}).text.encode('utf-8')
    return extension_script_data

def get_extension_pages(script_data):
    """Put the output of get_extension_script into this"""
    json_data = json.loads(script_data)
    return json_data
    #return json_data["initialmodeldata"]

def get_ext_endings(script_data):
    """Get anything of the form "ext/#-word" from the script data"""
    ext_re = r"\"(ext\/[0-9]+\-[a-z\-]+)\""
    results = re.findall(ext_re, script_data)
    return set(results)

def scrape_category(url):
    r = Render(url)
    result = r.frame.toHtml()
    print(result)
    return result

def loop_over_categories():
    categories = get_ext_endings(get_extension_script(starting_url))
    prefix = "https://chrome.google.com/webstore/category/"
    #for category in categories:
        #scrape_category(prefix + category)
    scrape_category("https://chrome.google.com/webstore/category/6-news")

loop_over_categories()

